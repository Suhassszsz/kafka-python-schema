This project demonstrates how to use Apache Kafka with Confluent Schema Registry and Avro schemas in Python.
It covers producers, consumers, schema evolution, and compatibility modes.

ðŸ“‚ Project Structure
- kafka-python-schema/
  
â”‚â”€â”€ avro_schemas/

   â”œâ”€â”€ payment_v1.avsc   

   â””â”€â”€ payment_v2.avsc         

â”‚â”€â”€ producer_v1.py       

â”‚â”€â”€ producer_v2.py    

â”‚â”€â”€ consumer.py       

â”‚â”€â”€ requirements.txt  

â”‚â”€â”€ docker-compose.yml      

â”‚â”€â”€ images/                     


ðŸš€ Setup Instructions

1. Start Kafka + Schema Registry

Make sure Docker and Docker Compose are installed. Then run:

- docker-compose up -d


This starts:

Zookeeper â†’ localhost:2181

Kafka Broker â†’ localhost:9092

Schema Registry â†’ http://localhost:8081


2. Create the topic
- docker exec -it kafka-python-schema-broker-1 kafka-topics \
  --create --topic transactions \
  --bootstrap-server broker:29092 \
  --partitions 1 --replication-factor 1


3. Install Python dependencies
- pip install -r requirements.txt

4. Run Consumer

Start the consumer to watch messages:

- python3 consumer.py

5. Run Producers

In another terminal, run v1 producer:

- python3 producer_v1.py


Then run v2 producer:

- python3 producer_v2.py

ðŸ“œ Schema Evolution & Compatibility

Schema v1 (payment_v1.avsc):

{"id": "string", "amount": "double"}


Schema v2 (payment_v2.avsc):

{"id": "string", "amount": "double", "currency": "string (default: USD)"}


Because currency has a default, this change is backward compatible:

Old consumers (v1) can still read new messages â†’ they just ignore currency.

New consumers (v2) can read both old and new messages.

ðŸ”‘
